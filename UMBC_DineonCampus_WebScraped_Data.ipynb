{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeWHJ4Krx-5R",
        "outputId": "8c2fcae2-a868-4056-e935-24c534d953f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to 'true_grits_breakfast_menu_data.csv'.\n",
            "Data successfully saved to 'true_grits_lunch_menu_data.csv'.\n",
            "Data successfully saved to 'true_grits_dinner_menu_data.csv'.\n",
            "Data successfully saved to 'commons_halal_shack_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_2.mato_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_wild_greens_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_dunkin_donuts_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_copperhead_jacks_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_the_skylight_room_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_absurd_bird_&_burgers_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'commons_indian_kitchen_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'aok_library_einstein_brothers_bagels_everyday_menu_data.csv'.\n",
            "Data successfully saved to 'university_center_chick-fil-a_menu_data.csv'.\n",
            "Data successfully saved to 'university_center_starbucks_menu_data.csv'.\n",
            "Data successfully saved to 'admin_the_coffee_shop_breakfast_menu_data.csv'.\n",
            "Data successfully saved to 'admin_the_coffee_shop_lunch_menu_data.csv'.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import requests\n",
        "\n",
        "# URLs for different meal periods from the UMBC website\n",
        "urls = {\n",
        "    'True Grits Breakfast': 'https://api.dineoncampus.com/v1/location/61f9d7c8a9f13a15d7c1a25e/periods/66cb8802351d53058fe9e806?platform=0&date=2024-10-10',\n",
        "    'True Grits Lunch': 'https://api.dineoncampus.com/v1/location/61f9d7c8a9f13a15d7c1a25e/periods/66cb8803351d53058fe9e829?platform=0&date=2024-10-10',\n",
        "    'True Grits Dinner': 'https://api.dineoncampus.com/v1/location/61f9d7c8a9f13a15d7c1a25e/periods/66cb8802351d53058fe9e815?platform=0&date=2024-10-10',\n",
        "    'Commons Halal Shack Everyday':'https://api.dineoncampus.com/v1/location/5d5ad0294198d40d234ea0ff/periods?platform=0&date=2024-10-10',\n",
        "    'Commons 2.Mato Everyday':'https://api.dineoncampus.com/v1/location/587e7b3fee596fb55f0c30d2/periods?platform=0&date=2024-10-10',\n",
        "    'Commons Wild Greens Everyday':'https://api.dineoncampus.com/v1/location/588f463b3191a2497a4cc091/periods?platform=0&date=2024-10-10',\n",
        "    'Commons Dunkin Donuts Everyday':'https://api.dineoncampus.com/v1/location/5d5acf41c4b7ff0f10147f4a/periods?platform=0&date=2024-10-10',\n",
        "    'Commons Copperhead Jacks Everyday':'https://api.dineoncampus.com/v1/location/65369077c625af08babdef53/periods?platform=0&date=2024-10-10',\n",
        "    'Commons The Skylight Room Everyday':'https://api.dineoncampus.com/v1/location/5b97c25e1178e90d90a74099/periods?platform=0&date=2024-10-10',\n",
        "    'Commons Absurd Bird & Burgers Everyday':'https://api.dineoncampus.com/v1/location/587f9cf7ee596fb5350cc155/periods?platform=0&date=2024-10-10',\n",
        "    'Commons Indian Kitchen Everyday':'https://api.dineoncampus.com/v1/location/64ef51dee45d430b6f906839/periods?platform=0&date=2024-10-10',\n",
        "    'AOK Library Einstein Brothers Bagels Everyday':'https://api.dineoncampus.com/v1/location/5b7dd40174cebf0e179513ae/periods?platform=0&date=2024-10-10',\n",
        "    'University Center Chick-fil-A':'https://api.dineoncampus.com/v1/location/587fc4143191a2391c28ecc0/periods?platform=0&date=2024-10-10',\n",
        "    'University Center Starbucks':'https://api.dineoncampus.com/v1/location/587fc52c3191a23aa828ecc5/periods?platform=0&date=2024-10-10',\n",
        "    'Admin The Coffee Shop Breakfast':'https://api.dineoncampus.com/v1/location/586bcfa12cc8da3d267f4682/periods?platform=0&date=2024-10-10',\n",
        "    'Admin The Coffee Shop Lunch':'https://api.dineoncampus.com/v1/location/586bcfa12cc8da3d267f4682/periods/64ed093d351d53079eba5649?platform=0&date=2024-10-10'\n",
        "}\n",
        "\n",
        "# Adding headers to mimic a browser\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "}\n",
        "\n",
        "# Looping through each URL and scraping the data\n",
        "for meal, url in urls.items():\n",
        "    # Send a request to the API with headers\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Checking if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        menu = data.get('menu', {})\n",
        "\n",
        "        # Handling Periods\n",
        "        periods = menu.get('periods', [])\n",
        "\n",
        "        # Creating a CSV file and writing the headers\n",
        "        file_name = f'{meal.replace(\" \", \"_\").lower()}_menu_data.csv'\n",
        "        with open(file_name, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            # Write the header\n",
        "            writer.writerow(['Meal Period', 'Category', 'Item Name', 'Portion', 'Description', 'Calories', 'Ingredients', 'Nutrients', 'Filters'])\n",
        "\n",
        "            # Considering 'periods' might be an object, adjusting the iteration:\n",
        "            if isinstance(periods, list):\n",
        "                # If periods is a list, looping it to iterate\n",
        "                for period in periods:\n",
        "                    period_name = period.get('name', 'Unknown Period')\n",
        "\n",
        "                    # Looping through categories within a period\n",
        "                    for category in period.get('categories', []):\n",
        "                        category_name = category.get('name', 'Unknown Category')\n",
        "\n",
        "                        # Looping through items within a category\n",
        "                        for item in category.get('items', []):\n",
        "                            item_name = item.get('name', 'Unknown Item')\n",
        "                            portion = item.get('portion', 'N/A')\n",
        "                            description = item.get('desc', 'No description available')\n",
        "                            calories = item.get('calories', 'N/A')\n",
        "                            ingredients = item.get('ingredients', 'N/A')\n",
        "\n",
        "                            # Extractinging nutrients, with fallback for missing 'uom'\n",
        "                            nutrients = ', '.join([f\"{nutrient['name']}: {nutrient['value']} {nutrient.get('uom', '')}\" for nutrient in item.get('nutrients', [])])\n",
        "\n",
        "                            # Extracting filters (e.g., allergens, labels)\n",
        "                            filters = ', '.join([filt['name'] for filt in item.get('filters', [])])\n",
        "\n",
        "                            # Writing the row for each item\n",
        "                            writer.writerow([period_name, category_name, item_name, portion, description, calories, ingredients, nutrients, filters])\n",
        "            else:\n",
        "                # If periods is not a list, to handle it directly\n",
        "                period_name = periods.get('name', 'Unknown Period')\n",
        "\n",
        "                # Looping through categories within the period\n",
        "                for category in periods.get('categories', []):\n",
        "                    category_name = category.get('name', 'Unknown Category')\n",
        "\n",
        "                    # Looping through items within a category\n",
        "                    for item in category.get('items', []):\n",
        "                        item_name = item.get('name', 'Unknown Item')\n",
        "                        portion = item.get('portion', 'N/A')\n",
        "                        description = item.get('desc', 'No description available')\n",
        "                        calories = item.get('calories', 'N/A')\n",
        "                        ingredients = item.get('ingredients', 'N/A')\n",
        "\n",
        "                        # Extracting nutrients, with fallback for missing 'uom'\n",
        "                        nutrients = ', '.join([f\"{nutrient['name']}: {nutrient['value']} {nutrient.get('uom', '')}\" for nutrient in item.get('nutrients', [])])\n",
        "\n",
        "                        # Extracting filters (e.g., allergens, labels)\n",
        "                        filters = ', '.join([filt['name'] for filt in item.get('filters', [])])\n",
        "\n",
        "                        # Writing the row for each item\n",
        "                        writer.writerow([period_name, category_name, item_name, portion, description, calories, ingredients, nutrients, filters])\n",
        "\n",
        "        print(f\"Data successfully saved to '{file_name}'.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve data for {meal}. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tg0jZBWbyAaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}